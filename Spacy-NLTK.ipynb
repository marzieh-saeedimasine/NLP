{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a9a4ee2-8390-4473-8a7f-b5eadd1aa98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk      # NLTK (Natural Language Toolkit)\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# !pip install spacy\n",
    "# !python3 -m spacy download en      #spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473db0bc-1e8f-49f7-9d9a-d5163af2b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import  sent_tokenize, word_tokenize  \n",
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a63c9c9b-ba04-491c-993b-07ece27333f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An end to end NLP project consists of many steps. 11\n",
      "An\n",
      "end\n",
      "to\n",
      "end\n",
      "NLP\n",
      "project\n",
      "consists\n",
      "of\n",
      "many\n",
      "steps\n",
      ".\n",
      "These steps together forms an NLP pipeline. 8\n",
      "These\n",
      "steps\n",
      "together\n",
      "forms\n",
      "an\n",
      "NLP\n",
      "pipeline\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "doc=nlp(\"An end to end NLP project consists of many steps. These steps together forms an NLP pipeline.\")\n",
    "\n",
    "for sentense in doc.sents:\n",
    "    print(sentense, len(sentense))\n",
    "    for word in sentense:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aceb42ed-0745-4562-8f8e-25b3b4820ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An end to end NLP project consists of many steps.', 'These steps together forms an NLP pipeline.']\n",
      "['An', 'end', 'to', 'end', 'NLP', 'project', 'consists', 'of', 'many', 'steps', '.', 'These', 'steps', 'together', 'forms', 'an', 'NLP', 'pipeline', '.']\n"
     ]
    }
   ],
   "source": [
    "doc=sent_tokenize(\"An end to end NLP project consists of many steps. These steps together forms an NLP pipeline.\")\n",
    "print(doc)\n",
    "\n",
    "doc=word_tokenize(\"An end to end NLP project consists of many steps. These steps together forms an NLP pipeline.\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33c920-84c1-4a15-b3df-114c0d3d4865",
   "metadata": {},
   "source": [
    "# Make a spacy blank object that just have tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "682b84f7-cb0b-47aa-b729-7b8a7295ee36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.blank(\"en\")  #blank lang model just have tokenizer\n",
    "type(nlp)\n",
    "nlp.pipe_names  #It is a blank pipeline. we should add different features to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3357601c-3a3d-4af9-bfd1-ca3525314c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      "as\n",
      "it\n",
      "costs\n",
      "only\n",
      "2\n",
      "$\n",
      "per\n",
      "plate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f32eb734-785e-4cf8-b9df-a15cd5905980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy token attribute are discribed below, these (.lemma_, .pos_ , .dep_) are not available for blank spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6240b3d0-a6d5-4142-8ba1-1a5a8faa9e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].text\n",
    "doc[0].is_currency\n",
    "doc[0].is_stop\n",
    "doc[0].i  #token index\n",
    "doc[0].like_num\n",
    "doc[0].is_punct\n",
    "doc[0].is_oov "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f43480f2-29ce-403d-a186-410640455159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span=doc[:4]\n",
    "type(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b5ff60e-cf86-4e09-a8a8-7e6e5adee5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"students.txt\") as f:\n",
    "   text=f.readlines()\n",
    "    \n",
    "text_tot=''.join(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6e5a667b-5780-4dc0-879e-13fc7cff9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(text_tot)\n",
    "email_list=[]\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        email_list.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "44914871-73d3-4a64-b90c-9592195aec75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[virat@kohli.com, maria@sharapova.com, serena@williams.com, joe@root.com]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff64e4d-a26e-46ea-8f1a-c6e6c771f3cf",
   "metadata": {},
   "source": [
    "# Customize the nlp object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aab79315-bd10-463b-9b07-3e6eb2fe725b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens=[token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "de6fcea6-a8e7-4839-809e-2d75d0b28bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer.add_special_case(\"gimme\",[{ORTH:'gim'},{ORTH:'me'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fa5f62bc-417f-4a96-ab2f-559ef232f9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens=[token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3076ab20-199c-448e-958c-6e47d494fed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m doc\u001b[38;5;241m=\u001b[39mnlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn end to end NLP project consists of many steps. These steps together forms an NLP pipeline.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentense\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentense\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentense\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/spacy/tokens/doc.pyx:923\u001b[0m, in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "doc=nlp(\"An end to end NLP project consists of many steps. These steps together forms an NLP pipeline.\")\n",
    "\n",
    "for sentense in doc.sents:\n",
    "    print(sentense, len(sentense))\n",
    "    for word in sentense:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec8d2e98-c82c-467b-bcc5-c7d9559c71d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E007] 'sentencizer' already exists in pipeline. Existing names: ['sentencizer']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentencizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m nlp\u001b[38;5;241m.\u001b[39mpipe_names\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/spacy/language.py:810\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    808\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE007\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names))\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Overriding pipe name in the config is not supported and will be ignored.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "\u001b[0;31mValueError\u001b[0m: [E007] 'sentencizer' already exists in pipeline. Existing names: ['sentencizer']"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "93fa8bc3-59fb-4ee9-87f2-48015756d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An end to end NLP project consists of many steps. 11\n",
      "An\n",
      "end\n",
      "to\n",
      "end\n",
      "NLP\n",
      "project\n",
      "consists\n",
      "of\n",
      "many\n",
      "steps\n",
      ".\n",
      "These steps together forms an NLP pipeline. 8\n",
      "These\n",
      "steps\n",
      "together\n",
      "forms\n",
      "an\n",
      "NLP\n",
      "pipeline\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"An end to end NLP project consists of many steps. These steps together forms an NLP pipeline.\")\n",
    "\n",
    "for sentense in doc.sents:\n",
    "    print(sentense, len(sentense))\n",
    "    for word in sentense:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2dfd6dc6-cd0c-4b7a-98ae-b48543c76116",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f7e76f1e-00d4-4b96-9ceb-d41be3e142e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(text)\n",
    "url_list=[]\n",
    "for token in doc:\n",
    "    if token.like_url:\n",
    "        url_list.append(token.text)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "42eb3f34-0a69-4a21-812f-e66389073567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.data.gov/',\n",
       " 'http://www.science',\n",
       " 'http://data.gov.uk/.',\n",
       " 'http://www3.norc.org/gss+website/',\n",
       " 'http://www.europeansocialsurvey.org/.']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3c199ad4-f83f-4f81-a0e3-c1079bb962e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "614170b6-75a8-4429-9565-99fd00cc5890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(transactions)\n",
    "for token in doc:\n",
    "    if token.like_num:\n",
    "        if doc[(token.i)+1].is_currency:  \n",
    "            print(token.text, doc[(token.i)+1])       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0625df7-309a-48af-98ad-14e5bfc05d82",
   "metadata": {},
   "source": [
    "# Make a spacy pipeline contains: tagger(.pos_), parser, lemmatizer(.lemma_),ner(.ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "438e17b4-f81b-4a18-826d-61d6a4923fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "nlp.pipe_names\n",
    "#nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0beb68e-9001-4b5f-a2df-5a555ac5a5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captain  |  PROPN proper noun  |  Captain\n",
      "america  |  PROPN proper noun  |  america\n",
      "ate  |  VERB verb  |  eat\n",
      "100  |  NUM numeral  |  100\n",
      "$  |  NUM numeral  |  $\n",
      "of  |  ADP adposition  |  of\n",
      "samosa  |  PROPN proper noun  |  samosa\n",
      ".  |  PUNCT punctuation  |  .\n",
      "Then  |  ADV adverb  |  then\n",
      "he  |  PRON pronoun  |  he\n",
      "said  |  VERB verb  |  say\n",
      "I  |  PRON pronoun  |  I\n",
      "can  |  AUX auxiliary  |  can\n",
      "do  |  VERB verb  |  do\n",
      "this  |  PRON pronoun  |  this\n",
      "all  |  DET determiner  |  all\n",
      "day  |  NOUN noun  |  day\n",
      ".  |  PUNCT punctuation  |  .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.pos_, spacy.explain(token.pos_), \" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ff9fb194-c33e-47c1-b89e-82cb8459eed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc  |  ORG\n",
      "$45 billion  |  MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text ,\" | \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "80b94ee4-6783-424c-8836-d3e8ab01a70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire twitter for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9b9352d9-3636-4ba8-bfaa-3aae0a3f84d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9227522eb44f405bacca97e30bd54994-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Tesla</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Inc</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">acquire</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">twitter</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">45</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-4\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9227522eb44f405bacca97e30bd54994-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9227522eb44f405bacca97e30bd54994-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5835fec-f977-453b-b8f1-d06365507738",
   "metadata": {},
   "source": [
    "# add_pipe to the blank pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c38d2-79d2-4d26-bbfe-3b3faf99bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_source=spacy.load('en_core_web_sm')\n",
    "nlp=spacy.blank(\"en\")\n",
    "#nlp.pipeline\n",
    "nlp.add_pipe(\"ner\", source=nlp_source)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8583b3-f473-4365-84a9-13dacaafc67f",
   "metadata": {},
   "source": [
    "# spacy for swedish lang processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6261f296-0fd2-4e8d-900d-b2d799d40745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download sv_core_news_sm\n",
    "#!python3 -m spacy download sv_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1c81a30-4ad8-427f-81de-5012252831ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'morphologizer',\n",
       " 'parser',\n",
       " 'lemmatizer',\n",
       " 'attribute_ruler',\n",
       " 'ner']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"sv_core_news_sm\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05ae82b6-ea10-4a6e-84fe-cfd67ec194bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla  |  ADJ adjective  |  tesla\n",
      "Inc  |  NOUN noun  |  Inc\n",
      "kommer  |  AUX auxiliary  |  komma\n",
      "att  |  PART particle  |  att\n",
      "förvärva  |  VERB verb  |  förvärva\n",
      "twitter  |  NOUN noun  |  twitt\n",
      "för  |  ADP adposition  |  för\n",
      "45  |  NUM numeral  |  45\n",
      "miljarder  |  NOUN noun  |  miljard\n",
      "dollar  |  NOUN noun  |  doll\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc kommer att förvärva twitter för 45 miljarder dollar\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.pos_ , spacy.explain(token.pos_),\" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "690e1c33-7484-4ff3-b25a-6e2cd95805b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 miljarder dollar  |  MSR\n"
     ]
    }
   ],
   "source": [
    "nlp_source=spacy.load('sv_core_news_lg')\n",
    "\n",
    "doc = nlp_source(\"Tesla Inc kommer att förvärva twitter för 45 miljarder dollar\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\" | \",ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58fea3c9-ec79-4e60-aa48-bf0374132c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read more in https://spacy.io/usage/processing-pipelines#pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
